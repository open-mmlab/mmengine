# ä¼˜åŒ–å™¨å°è£…ï¼ˆOptimWrapperï¼‰

MMEngine å®ç°äº†ä¼˜åŒ–å™¨å°è£…ï¼Œä¸ºç”¨æˆ·æä¾›äº†ç»Ÿä¸€çš„ä¼˜åŒ–å™¨è®¿é—®æ¥å£ã€‚ä¼˜åŒ–å™¨å°è£…æ”¯æŒä¸åŒçš„è®­ç»ƒç­–ç•¥ï¼ŒåŒ…æ‹¬æ··åˆç²¾åº¦è®­ç»ƒã€æ¢¯åº¦ç´¯åŠ å’Œæ¢¯åº¦æˆªæ–­ã€‚ç”¨æˆ·å¯ä»¥æ ¹æ®éœ€æ±‚é€‰æ‹©åˆé€‚çš„è®­ç»ƒç­–ç•¥ã€‚ä¼˜åŒ–å™¨å°è£…è¿˜å®šä¹‰äº†ä¸€å¥—æ ‡å‡†çš„å‚æ•°æ›´æ–°æµç¨‹ï¼Œç”¨æˆ·å¯ä»¥åŸºäºè¿™ä¸€å¥—æµç¨‹ï¼Œå®ç°åŒä¸€å¥—ä»£ç ï¼Œä¸åŒè®­ç»ƒç­–ç•¥çš„åˆ‡æ¢ã€‚

## ä¼˜åŒ–å™¨å°è£… vs ä¼˜åŒ–å™¨

è¿™é‡Œæˆ‘ä»¬åˆ†åˆ«åŸºäº Pytorch å†…ç½®çš„ä¼˜åŒ–å™¨å’Œ MMEngine çš„ä¼˜åŒ–å™¨å°è£…è¿›è¡Œå•ç²¾åº¦è®­ç»ƒã€æ··åˆç²¾åº¦è®­ç»ƒå’Œæ¢¯åº¦ç´¯åŠ ï¼Œå¯¹æ¯”äºŒè€…å®ç°ä¸Šçš„åŒºåˆ«ã€‚

### è®­ç»ƒæ¨¡å‹

**1.1 åŸºäº Pytorch çš„ SGD ä¼˜åŒ–å™¨å®ç°å•ç²¾åº¦è®­ç»ƒ**

```python
import torch
from torch.optim import SGD
import torch.nn as nn
import torch.nn.functional as F

inputs = [torch.zeros(10, 1, 1)] * 10
targets = [torch.ones(10, 1, 1)] * 10
model = nn.Linear(1, 1)
optimizer = SGD(model.parameters(), lr=0.01)
optimizer.zero_grad()

for input, target in zip(inputs, targets):
    output = model(input)
    loss = F.l1_loss(output, target)
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
```

**1.2 ä½¿ç”¨ MMEngine çš„ä¼˜åŒ–å™¨å°è£…å®ç°å•ç²¾åº¦è®­ç»ƒ**

```python
from mmengine.optim import OptimWrapper

optim_wrapper = OptimWrapper(optimizer=optimizer)

for input, target in zip(inputs, targets):
    output = model(input)
    loss = F.l1_loss(output, target)
    optim_wrapper.update_params(loss)
```

![image](https://user-images.githubusercontent.com/57566630/185605436-17f08083-b219-4b38-b714-eb891f7a8e56.png)

ä¼˜åŒ–å™¨å°è£…çš„ `update_params` å®ç°äº†æ ‡å‡†çš„æ¢¯åº¦è®¡ç®—ã€å‚æ•°æ›´æ–°å’Œæ¢¯åº¦æ¸…é›¶æµç¨‹ï¼Œå¯ä»¥ç›´æ¥ç”¨æ¥æ›´æ–°æ¨¡å‹å‚æ•°ã€‚

**2.1 åŸºäº Pytorch çš„ SGD ä¼˜åŒ–å™¨å®ç°æ··åˆç²¾åº¦è®­ç»ƒ**

```python
from torch.cuda.amp import autocast

model = model.cuda()
inputs = [torch.zeros(10, 1, 1, 1)] * 10
targets = [torch.ones(10, 1, 1, 1)] * 10

for input, target in zip(inputs, targets):
    with autocast():
        output = model(input.cuda())
    loss = F.l1_loss(output, target.cuda())
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
```

**2.2 åŸºäº MMEngine çš„ ä¼˜åŒ–å™¨å°è£…å®ç°æ··åˆç²¾åº¦è®­ç»ƒ**

```python
from mmengine.optim import AmpOptimWrapper

optim_wrapper = AmpOptimWrapper(optimizer=optimizer)

for input, target in zip(inputs, targets):
    with optim_wrapper.optim_context(model):
        output = model(input.cuda())
    loss = F.l1_loss(output, target.cuda())
    optim_wrapper.update_params(loss)
```

![image](https://user-images.githubusercontent.com/57566630/185606060-2fdebd90-c17a-4a8c-aaf1-540d47975c59.png)

å¼€åˆæ··åˆç²¾åº¦è®­ç»ƒéœ€è¦ä½¿ç”¨ `AmpOptimWrapper`ï¼Œä»–çš„ optim_context æ¥å£ç±»ä¼¼ `autocast`ï¼Œä¼šå¼€å¯æ··åˆç²¾åº¦è®­ç»ƒçš„ä¸Šä¸‹æ–‡ã€‚é™¤æ­¤ä¹‹å¤–ä»–è¿˜èƒ½åŠ é€Ÿåˆ†å¸ƒå¼è®­ç»ƒæ—¶çš„æ¢¯åº¦ç´¯åŠ ï¼Œè¿™ä¸ªæˆ‘ä»¬ä¼šåœ¨ä¸‹ä¸€ä¸ªç¤ºä¾‹ä¸­ä»‹ç»

**3.1 åŸºäº Pytorch çš„ SGD ä¼˜åŒ–å™¨å®ç°æ··åˆç²¾åº¦è®­ç»ƒå’Œæ¢¯åº¦ç´¯åŠ **

```python
for idx, (input, target) in enumerate(zip(inputs, targets)):
    with autocast():
        output = model(input.cuda())
    loss = F.l1_loss(output, target.cuda())
    loss.backward()
    if idx % 2 == 0:
        optimizer.step()
        optimizer.zero_grad()
```

**3.2 åŸºäº MMEngine çš„ä¼˜åŒ–å™¨å°è£…å®ç°æ··åˆç²¾åº¦è®­ç»ƒå’Œæ¢¯åº¦ç´¯åŠ **

```python
optim_wrapper = AmpOptimWrapper(optimizer=optimizer, accumulative_counts=2)

for input, target in zip(inputs, targets):
    with optim_wrapper.optim_context(model):
        output = model(input.cuda())
    loss = F.l1_loss(output, target.cuda())
    optim_wrapper.update_params(loss)
```

![image](https://user-images.githubusercontent.com/57566630/185608932-91a082d4-1bf4-4329-b283-98fbbc20b5f7.png)

æˆ‘ä»¬åªéœ€è¦é…ç½® `accumulative_counts` å‚æ•°ï¼Œå¹¶è°ƒç”¨ `update_params` æ¥å£å°±èƒ½å®ç°æ¢¯åº¦ç´¯åŠ çš„åŠŸèƒ½ã€‚é™¤æ­¤ä¹‹å¤–ï¼Œåˆ†å¸ƒå¼è®­ç»ƒæƒ…å†µä¸‹ï¼Œå¦‚æœæˆ‘ä»¬é…ç½®æ¢¯åº¦ç´¯åŠ çš„åŒæ—¶å¼€å¯äº† `optim_wrapper` ä¸Šä¸‹æ–‡ï¼Œå¯ä»¥é¿å…æ¢¯åº¦ç´¯åŠ é˜¶æ®µä¸å¿…è¦çš„æ¢¯åº¦åŒæ­¥ã€‚

ä¼˜åŒ–å™¨å°è£…åŒæ ·æä¾›äº†æ›´ç»†ç²’åº¦çš„æ¥å£ï¼Œæ–¹ä¾¿ç”¨æˆ·å®ç°ä¸€äº›è‡ªå®šä¹‰çš„å‚æ•°æ›´æ–°é€»è¾‘ï¼š

- `backward`ï¼šä¼ å…¥æŸå¤±ï¼Œç”¨äºè®¡ç®—å‚æ•°æ¢¯åº¦ï¼Œã€‚
- `step`ï¼š åŒ `optimizer.step`ï¼Œç”¨äºæ›´æ–°å‚æ•°ã€‚
- `zero_grad`ï¼š åŒ `optimizer.zero_grad`ï¼Œç”¨äºå‚æ•°çš„æ¢¯åº¦ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸Šè¿°æ¥å£å®ç°å’Œ Pytorch ä¼˜åŒ–å™¨ç›¸åŒçš„å‚æ•°æ›´æ–°é€»è¾‘ï¼š

```python
for idx, (input, target) in enumerate(zip(inputs, targets)):
    optimizer.zero_grad()
    with optim_wrapper.optim_context(model):
        output = model(input.cuda())
    loss = F.l1_loss(output, target.cuda())
    optim_wrapper.backward(loss)
    if idx % 2 == 0:
        optim_wrapper.step()
        optim_wrapper.zero_grad()
```

### è·å–å­¦ä¹ ç‡/åŠ¨é‡ï¼š

ä¼˜åŒ–å™¨å°è£…æä¾›äº† `get_lr` å’Œ `get_momentum` æ¥å£ç”¨äºè·å–ä¼˜åŒ–å™¨çš„ä¸€ä¸ªå‚æ•°ç»„çš„å­¦ä¹ ç‡

```python
import torch.nn as nn
from torch.optim import SGD

from mmengine.optim import OptimWrapper

model = nn.Linear(1, 1)
optimizer = SGD(model.parameters(), lr=0.01)
optim_wrapper = OptimWrapper(optimizer)

print(optimizer.param_groups[0]['lr'])  # -1.01
print(optimizer.param_groups[0]['momentum'])  # 0
print(optim_wrapper.get_lr())  # {'lr': [0.01]}
print(optim_wrapper.get_momentum())  # {'momentum': [0]}
```

```
0.01
0
{'lr': [0.01]}
{'momentum': [0]}
```

### å¯¼å‡º/åŠ è½½çŠ¶æ€å­—å…¸

ä¼˜åŒ–å™¨å°è£…å’Œä¼˜åŒ–å™¨ä¸€æ ·ï¼Œæä¾›äº† `state_dict` å’Œ `load_state_dict` æ¥å£ï¼Œç”¨äºå¯¼å‡º/åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œå¯¹äº `AmpOptimWrapper`ï¼Œä¼˜åŒ–å™¨å°è£…è¿˜ä¼šé¢å¤–å¯¼å‡ºæ··åˆç²¾åº¦è®­ç»ƒç›¸å…³çš„å‚æ•°ï¼š

```python
import torch.nn as nn
from torch.optim import SGD
from mmengine.optim import OptimWrapper, AmpOptimWrapper

model = nn.Linear(1, 1)
optimizer = SGD(model.parameters(), lr=0.01)

optim_wapper = OptimWrapper(optimizer=optimizer)
amp_optim_wapper = AmpOptimWrapper(optimizer=optimizer)

# å¯¼å‡ºçŠ¶æ€å­—å…¸
optim_state_dict = optim_wapper.state_dict()
amp_optim_state_dict = amp_optim_wapper.state_dict()

print(optim_state_dict)
print(amp_optim_state_dict)
optim_wapper_new = OptimWrapper(optimizer=optimizer)
amp_optim_wapper_new = AmpOptimWrapper(optimizer=optimizer)

# åŠ è½½çŠ¶æ€å­—å…¸
amp_optim_wapper_new.load_state_dict(amp_optim_state_dict)
optim_wapper_new.load_state_dict(optim_state_dict)
```

```
{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0, 1]}]}
{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'params': [0, 1]}], 'loss_scaler': {'scale': 65536.0, 'growth_factor': 2.0, 'backoff_factor': 0.5, 'growth_interval': 2000, '_growth_tracker': 0}}
```

### ä½¿ç”¨å¤šä¸ªä¼˜åŒ–å™¨

è€ƒè™‘åˆ°ç”Ÿæˆå¯¹æŠ—ç½‘ç»œä¹‹ç±»çš„ç®—æ³•é€šå¸¸éœ€è¦ä½¿ç”¨å¤šä¸ªä¼˜åŒ–å™¨æ¥è®­ç»ƒç”Ÿæˆå™¨å’Œåˆ¤åˆ«å™¨ï¼Œå› æ­¤ä¼˜åŒ–å™¨å°è£…æä¾›äº†ä¼˜åŒ–å™¨å°è£…çš„å®¹å™¨ç±»ï¼š`OptimWrapperDict` æ¥ç®¡ç†å¤šä¸ªä¼˜åŒ–å™¨å°è£…ã€‚`OptimWrapperDict` ä»¥å­—å…¸çš„å½¢å¼å­˜å‚¨ä¼˜åŒ–å™¨å°è£…ï¼Œå¹¶å…è®¸ç”¨æˆ·åƒå­—å…¸ä¸€æ ·è®¿é—®ã€éå†å…¶ä¸­çš„å…ƒç´ ï¼Œå³ä¼˜åŒ–å™¨å°è£…å®ä¾‹ã€‚

ä¸æ™®é€šçš„ä¼˜åŒ–å™¨å°è£…ä¸åŒï¼Œ`OptimWrapperDict` æ²¡æœ‰å®ç° `update_params`ã€ `optim_context`, `backward`ã€`step` ç­‰æ–¹æ³•ï¼Œæ— æ³•è¢«ç›´æ¥ç”¨äºè®­ç»ƒæ¨¡å‹ã€‚æˆ‘ä»¬å»ºè®®ç›´æ¥è®¿é—® `OptimWrapperDict` ç®¡ç†çš„ä¼˜åŒ–å™¨å®ä¾‹ï¼Œæ¥å®ç°å‚æ•°æ›´æ–°é€»è¾‘ã€‚

ä½ æˆ–è®¸ä¼šå¥½å¥‡ï¼Œæ—¢ç„¶ `OptimWrapperDict` æ²¡æœ‰è®­ç»ƒçš„åŠŸèƒ½ï¼Œé‚£ä¸ºä»€ä¹ˆä¸ç›´æ¥ä½¿ç”¨ `dict` æ¥ç®¡ç†å¤šä¸ªä¼˜åŒ–å™¨ã€‚äº‹å®ä¸Šï¼Œ`OptimWrapperDict` çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯æ”¯æŒæ‰¹é‡å¯¼å‡º/åŠ è½½æ‰€æœ‰ä¼˜åŒ–å™¨å°è£…çš„çŠ¶æ€å­—å…¸ï¼›æ”¯æŒè·å–å¤šä¸ªä¼˜åŒ–å™¨å°è£…çš„å­¦ä¹ ç‡ã€åŠ¨é‡ã€‚å¦‚æœæ²¡æœ‰ `OptimWrapperDict`ï¼Œ`MMEngine` å°±éœ€è¦åœ¨å¾ˆå¤šä½ç½®å¯¹ä¼˜åŒ–å™¨å°è£…çš„ç±»å‹åš `if else` åˆ¤æ–­ï¼Œä»¥è·å–æ‰€æœ‰ä¼˜åŒ–å™¨å°è£…çš„çŠ¶æ€ã€‚

```python
from torch.optim import SGD
import torch.nn as nn

from mmengine.optim import OptimWrapper, OptimWrapperDict

gen = nn.Linear(1, 1)
disc = nn.Linear(1, 1)
optimizer_gen = SGD(gen.parameters(), lr=0.01)
optimizer_disc = SGD(disc.parameters(), lr=0.01)

optim_wapper_gen = OptimWrapper(optimizer=optimizer_gen)
optim_wapper_disc = OptimWrapper(optimizer=optimizer_disc)
optim_dict = OptimWrapperDict(gen=optim_wapper_gen, disc=optim_wapper_disc)

print(optim_dict.get_lr())  # {'gen.lr': [0.01], 'disc.lr': [0.01]}
print(optim_dict.get_momentum())  # {'gen.momentum': [0], 'disc.momentum': [0]}
```

```
{'gen.lr': [0.01], 'disc.lr': [0.01]}
{'gen.momentum': [0], 'disc.momentum': [0]}
```

å¦‚ä¸Šä¾‹æ‰€ç¤ºï¼Œ`OptimWrapperDict` å¯ä»¥éå¸¸æ–¹ä¾¿çš„å¯¼å‡ºæ‰€æœ‰ä¼˜åŒ–å™¨å°è£…çš„å­¦ä¹ ç‡å’ŒåŠ¨é‡ï¼ŒåŒæ ·çš„ï¼Œä¼˜åŒ–å™¨å°è£…ä¹Ÿèƒ½å¤Ÿå¯¼å‡º/åŠ è½½æ‰€æœ‰ä¼˜åŒ–å™¨å°è£…çš„çŠ¶æ€å­—å…¸ã€‚

## åœ¨[æ‰§è¡Œå™¨](https://mmengine.readthedocs.io/zh_CN/latest/tutorials/runner.html)ä¸­é…ç½®ä¼˜åŒ–å™¨å°è£…

### ç®€å•é…ç½®

ä¼˜åŒ–å™¨å°è£…éœ€è¦æ¥å— `optimizer` å‚æ•°ï¼Œå› æ­¤æˆ‘ä»¬é¦–å…ˆéœ€è¦ä¸ºä¼˜åŒ–å™¨å°è£…é…ç½® `optimizer`ã€‚
MMEngine ä¼šè‡ªåŠ¨å°† PyTorch ä¸­çš„æ‰€æœ‰ä¼˜åŒ–å™¨éƒ½æ·»åŠ è¿› `OPTIMIZERS` æ³¨å†Œè¡¨ä¸­ï¼Œç”¨æˆ·å¯ä»¥ç”¨å­—å…¸çš„å½¢å¼æ¥æŒ‡å®šä¼˜åŒ–å™¨ï¼Œæ‰€æœ‰æ”¯æŒçš„ä¼˜åŒ–å™¨è§ [PyTorch ä¼˜åŒ–å™¨åˆ—è¡¨](https://pytorch.org/docs/stable/optim.html#algorithms)ã€‚

ä»¥é…ç½®ä¸€ä¸ª SGD ä¼˜åŒ–å™¨å°è£…ä¸ºä¾‹ï¼š

```python
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optim_wrapper = dict(type='OptimWrapper', optimizer=optimizer)
```

è¿™æ ·æˆ‘ä»¬å°±é…ç½®å¥½äº†ä¸€ä¸ªä¼˜åŒ–å™¨ç±»å‹ä¸º SGD çš„ä¼˜åŒ–å™¨å°è£…ï¼Œå­¦ä¹ ç‡ã€åŠ¨é‡ç­‰å‚æ•°å¦‚é…ç½®æ‰€ç¤ºã€‚è€ƒè™‘åˆ° `OptimWrapper` ä¸ºæ ‡å‡†çš„å•ç²¾åº¦è®­ç»ƒï¼Œå› æ­¤æˆ‘ä»¬ä¹Ÿå¯ä»¥ä¸é…ç½® `type` å­—æ®µï¼š

```python
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optim_wrapper = dict(optimizer=optimizer)
```

è¦æƒ³å¼€å¯æ··åˆç²¾åº¦è®­ç»ƒå’Œæ¢¯åº¦ç´¯åŠ ï¼Œéœ€è¦å°† `type` åˆ‡æ¢æˆ `AmpOptimWrapper`ï¼Œå¹¶æŒ‡å®š `accumulative_counts` å‚æ•°

```python
optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)
optim_wrapper = dict(type='AmpOptimWrapper', optimizer=optimizer, accumulative_counts=2)
```

### è¿›é˜¶é…ç½®

PyTorch çš„ä¼˜åŒ–å™¨æ”¯æŒå¯¹æ¨¡å‹ä¸­çš„ä¸åŒå‚æ•°è®¾ç½®ä¸åŒçš„è¶…å‚æ•°ï¼Œä¾‹å¦‚å¯¹ä¸€ä¸ªåˆ†ç±»æ¨¡å‹çš„éª¨å¹²ï¼ˆbackboneï¼‰å’Œåˆ†ç±»å¤´ï¼ˆheadï¼‰è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡ï¼š

```python
from torch.optim import SGD
import torch.nn as nn

model = nn.ModuleDict(dict(backbone=nn.Linear(1, 1), head=nn.Linear(1, 1)))
optimizer = SGD([{'params': model.backbone.parameters()},
     {'params': model.head.parameters(), 'lr': 1e-3}],
    lr=0.01,
    momentum=0.9)
```

ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæ¨¡å‹çš„éª¨å¹²éƒ¨åˆ†ä½¿ç”¨äº† 0.01 å­¦ä¹ ç‡ï¼Œè€Œæ¨¡å‹çš„å¤´éƒ¨åˆ™ä½¿ç”¨äº† 1e-3 å­¦ä¹ ç‡ã€‚
ç”¨æˆ·å¯ä»¥å°†æ¨¡å‹çš„ä¸åŒéƒ¨åˆ†å‚æ•°å’Œå¯¹åº”çš„è¶…å‚ç»„æˆä¸€ä¸ªå­—å…¸çš„åˆ—è¡¨ä¼ ç»™ä¼˜åŒ–å™¨ï¼Œæ¥å®ç°å¯¹æ¨¡å‹ä¼˜åŒ–çš„ç»†ç²’åº¦è°ƒæ•´ã€‚

åœ¨ MMEngine ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä¼˜åŒ–å™¨å°è£…æ„é€ å™¨ï¼ˆoptimizer wrapper constructorï¼‰ï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿç›´æ¥é€šè¿‡è®¾ç½®ä¼˜åŒ–å™¨å°è£…é…ç½®æ–‡ä»¶ä¸­çš„ `paramwise_cfg` å­—æ®µè€Œéä¿®æ”¹ä»£ç æ¥å®ç°å¯¹æ¨¡å‹çš„ä¸åŒéƒ¨åˆ†è®¾ç½®ä¸åŒçš„è¶…å‚ã€‚

#### ä¸ºä¸åŒç±»å‹çš„å‚æ•°è®¾ç½®ä¸åŒçš„è¶…å‚ç³»æ•°

MMEngine æä¾›çš„é»˜è®¤ä¼˜åŒ–å™¨å°è£…æ„é€ å™¨æ”¯æŒå¯¹æ¨¡å‹ä¸­ä¸åŒç±»å‹çš„å‚æ•°è®¾ç½®ä¸åŒçš„è¶…å‚ç³»æ•°ã€‚
ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ `paramwise_cfg` ä¸­è®¾ç½® `norm_decay_mult=0` ï¼Œä»è€Œå°†æ­£åˆ™åŒ–å±‚ï¼ˆnormalization layerï¼‰çš„æƒé‡ï¼ˆweightï¼‰å’Œåç½®ï¼ˆbiasï¼‰çš„æƒå€¼è¡°å‡ç³»æ•°ï¼ˆweight decayï¼‰è®¾ç½®ä¸º 0ï¼Œ
æ¥å®ç° [Bag of Tricks](https://arxiv.org/abs/1812.01187) è®ºæ–‡ä¸­æåˆ°çš„ä¸å¯¹æ­£åˆ™åŒ–å±‚è¿›è¡Œæƒå€¼è¡°å‡çš„æŠ€å·§ã€‚

å…·ä½“ç¤ºä¾‹å¦‚ä¸‹ï¼Œæˆ‘ä»¬å°† `ToyModel` ä¸­æ‰€æœ‰æ­£åˆ™åŒ–å±‚ï¼ˆ`head.bn`ï¼‰çš„çš„æƒé‡è¡°å‡ç³»æ•°è®¾ç½®ä¸º 0ï¼š

```python
from mmengine.optim import build_optim_wrapper
from collections import OrderedDict

class ToyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.backbone = nn.ModuleDict(
            dict(layer0=nn.Linear(1, 1), layer1=nn.Linear(1, 1)))
        self.head = nn.Sequential(
            OrderedDict(
                linear=nn.Linear(1, 1),
                bn=nn.BatchNorm1d(1)))


optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.01, weight_decay=0.0001),
    paramwise_cfg=dict(norm_decay_mult=0))
optimizer = build_optim_wrapper(ToyModel(), optim_wrapper)
```

```
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.bias:lr=0.01
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.bias:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer1.bias:lr=0.01
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer1.bias:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.linear.bias:lr=0.01
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.linear.bias:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.bn.weight:weight_decay=0.0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.bn.bias:weight_decay=0.0
```

é™¤äº†å¯ä»¥å¯¹æ­£åˆ™åŒ–å±‚çš„æƒé‡è¡°å‡è¿›è¡Œé…ç½®å¤–ï¼ŒMMEngine çš„é»˜è®¤ä¼˜åŒ–å™¨å°è£…æ„é€ å™¨çš„ `paramwise_cfg` è¿˜æ”¯æŒå¯¹æ›´å¤šä¸åŒç±»å‹çš„å‚æ•°è®¾ç½®è¶…å‚ç³»æ•°ï¼Œæ”¯æŒçš„é…ç½®å¦‚ä¸‹ï¼š

`lr_mult`ï¼šæ‰€æœ‰å‚æ•°çš„å­¦ä¹ ç‡ç³»æ•°

`decay_mult`ï¼šæ‰€æœ‰å‚æ•°çš„è¡°å‡ç³»æ•°

`bias_lr_mult`ï¼šåç½®çš„å­¦ä¹ ç‡ç³»æ•°ï¼ˆä¸åŒ…æ‹¬æ­£åˆ™åŒ–å±‚çš„åç½®ä»¥åŠå¯å˜å½¢å·ç§¯çš„ offsetï¼‰ï¼Œé»˜è®¤å€¼ä¸º 1

`bias_decay_mult`ï¼šåç½®çš„æƒå€¼è¡°å‡ç³»æ•°ï¼ˆä¸åŒ…æ‹¬æ­£åˆ™åŒ–å±‚çš„åç½®ä»¥åŠå¯å˜å½¢å·ç§¯çš„ offsetï¼‰ï¼Œé»˜è®¤å€¼ä¸º 1

`norm_decay_mult`ï¼šæ­£åˆ™åŒ–å±‚æƒé‡å’Œåç½®çš„æƒå€¼è¡°å‡ç³»æ•°ï¼Œé»˜è®¤å€¼ä¸º 1

`dwconv_decay_mult`ï¼šDepth-wise å·ç§¯çš„æƒå€¼è¡°å‡ç³»æ•°ï¼Œé»˜è®¤å€¼ä¸º 1

`bypass_duplicate`ï¼šæ˜¯å¦è·³è¿‡é‡å¤çš„å‚æ•°ï¼Œé»˜è®¤ä¸º `False`

`dcn_offset_lr_mult`ï¼šå¯å˜å½¢å·ç§¯ï¼ˆDeformable Convolutionï¼‰çš„å­¦ä¹ ç‡ç³»æ•°ï¼Œé»˜è®¤å€¼ä¸º 1

#### ä¸ºæ¨¡å‹ä¸åŒéƒ¨åˆ†çš„å‚æ•°è®¾ç½®ä¸åŒçš„è¶…å‚ç³»æ•°

æ­¤å¤–ï¼Œä¸ä¸Šæ–‡ PyTorch çš„ç¤ºä¾‹ä¸€æ ·ï¼Œåœ¨ MMEngine ä¸­æˆ‘ä»¬ä¹ŸåŒæ ·å¯ä»¥å¯¹æ¨¡å‹ä¸­çš„ä»»æ„æ¨¡å—è®¾ç½®ä¸åŒçš„è¶…å‚ï¼Œåªéœ€è¦åœ¨ `paramwise_cfg` ä¸­è®¾ç½® `custom_keys` å³å¯ã€‚

ä¾‹å¦‚æˆ‘ä»¬æƒ³å°† `backbone.layer0` æ‰€æœ‰å‚æ•°çš„å­¦ä¹ ç‡è®¾ç½®ä¸º 0ï¼Œè¡°å‡ç³»æ•°è®¾ç½®ä¸º 0ï¼Œ`backbone` å…¶ä½™å­æ¨¡å—çš„å­¦ä¹ ç‡è®¾ç½®ä¸º 1ï¼›`head` æ‰€æ¬²å‚æ•°çš„å­¦ä¹ ç‡è®¾ç½®ä¸º 0.01ï¼Œå¯ä»¥è¿™æ ·é…ç½®ï¼š

```python
optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.01, weight_decay=0.0001),
    paramwise_cfg=dict(
        custom_keys={
            'backbone.layer0': dict(lr_mult=0, decay_mult=0),
            'backbone': dict(lr_mult=1),
            'head': dict(lr_mult=0.1)
        }))
optimizer = build_optim_wrapper(ToyModel(), optim_wrapper)
```

```
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.weight:lr=0.0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.weight:weight_decay=0.0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.weight:lr_mult=0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.weight:decay_mult=0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.bias:lr=0.0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.bias:weight_decay=0.0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.bias:lr_mult=0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer0.bias:decay_mult=0
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer1.weight:lr=0.01
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer1.weight:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer1.weight:lr_mult=1
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer1.bias:lr=0.01
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer1.bias:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- backbone.layer1.bias:lr_mult=1
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.linear.weight:lr=0.001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.linear.weight:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.linear.weight:lr_mult=0.1
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.linear.bias:lr=0.001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.linear.bias:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.linear.bias:lr_mult=0.1
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.bn.weight:lr=0.001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.bn.weight:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.bn.weight:lr_mult=0.1
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.bn.bias:lr=0.001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.bn.bias:weight_decay=0.0001
08/23 22:02:43 - mmengine - [4m[37mINFO[0m - paramwise_options -- head.bn.bias:lr_mult=0.1
```

ä¸Šä¾‹ä¸­ï¼Œæ¨¡å‹çš„çŠ¶æ€å­—å…¸çš„ `key` å¦‚ä¸‹ï¼š

```python
for name, val in ToyModel().named_parameters():
    print(name)
```

```
backbone.layer0.weight
backbone.layer0.bias
backbone.layer1.weight
backbone.layer1.bias
head.linear.weight
head.linear.bias
head.bn.weight
head.bn.bias
```

custom_keys ä¸­æ¯ä¸€ä¸ªå­—æ®µçš„å«ä¹‰å¦‚ä¸‹ï¼š

1. `'backbone': dict(lr_mult=1)`ï¼šå°†åå­—å‰ç¼€ä¸º `backbone` çš„å‚æ•°çš„å­¦ä¹ ç‡è®¾ç½®ä¸º 1
2. `'backbone.layer0': dict(lr_mult=0, decay_mult=0)`ï¼šå°†åå­—å‰ç¼€ä¸º `backbone.layer0` çš„å‚æ•°å­¦ä¹ ç‡è®¾ç½®ä¸º 0ï¼Œè¡°å‡ç³»æ•°è®¾ç½®ä¸º 0ï¼Œè¯¥é…ç½®ä¼˜å…ˆçº§æ¯”ç¬¬ä¸€æ¡é«˜
3. `'head': dict(lr_mult=0.1)`ï¼šå°†åå­—å‰ç¼€ä¸º `head` çš„å‚æ•°çš„å­¦ä¹ ç‡è®¾ç½®ä¸º 0.1

### è‡ªå®šä¹‰ä¼˜åŒ–å™¨æ„é€ ç­–ç•¥

ä¸ MMEngine ä¸­çš„å…¶ä»–æ¨¡å—ä¸€æ ·ï¼Œä¼˜åŒ–å™¨å°è£…æ„é€ å™¨ä¹ŸåŒæ ·ç”±[æ³¨å†Œè¡¨](https://mmengine.readthedocs.io/zh_CN/latest/tutorials/param_scheduler.html)ç®¡ç†ã€‚
æˆ‘ä»¬å¯ä»¥é€šè¿‡å®ç°è‡ªå®šä¹‰çš„ä¼˜åŒ–å™¨å°è£…æ„é€ å™¨æ¥å®ç°è‡ªå®šä¹‰çš„è¶…å‚è®¾ç½®ç­–ç•¥ã€‚

ä¾‹å¦‚ï¼Œæˆ‘ä»¬æƒ³å®ç°ä¸€ä¸ªå«åš `LayerDecayOptimWrapperConstructor` çš„ä¼˜åŒ–å™¨å°è£…æ„é€ å™¨ï¼Œèƒ½å¤Ÿå¯¹æ¨¡å‹ä¸åŒæ·±åº¦çš„å±‚è‡ªåŠ¨è®¾ç½®é€’å‡çš„å­¦ä¹ ç‡ï¼š

```python
from mmengine.optim import DefaultOptimWrapperConstructor
from mmengine.registry import OPTIM_WRAPPER_CONSTRUCTORS
from mmengine.logging import print_log


@OPTIM_WRAPPER_CONSTRUCTORS.register_module(force=True)
class LayerDecayOptimizerConstructor(DefaultOptimWrapperConstructor):

    def __init__(self, optim_wrapper_cfg, paramwise_cfg=None):
        super().__init__(optim_wrapper_cfg, paramwise_cfg=None)
        self.decay_factor = paramwise_cfg.get('decay_factor', 0.5)

        super().__init__(optim_wrapper_cfg, paramwise_cfg)

    def add_params(self, params, module, prefix='' ,lr=None):
        if lr is None:
            lr = self.base_lr

        for name, param in module.named_parameters(recurse=False):
            param_group = dict()
            param_group['params'] = [param]
            param_group['lr'] = lr
            params.append(param_group)
            full_name = f'{prefix}.{name}' if prefix else name
            print_log(f'{full_name} : lr={lr}', logger='current')

        for name, module in module.named_children():
            chiled_prefix = f'{prefix}.{name}' if prefix else name
            self.add_params(
                params, module, chiled_prefix, lr=lr * self.decay_factor)


class ToyModel(nn.Module):

    def __init__(self) -> None:
        super().__init__()
        self.layer = nn.ModuleDict(dict(linear=nn.Linear(1, 1)))
        self.linear = nn.Linear(1, 1)


model = ToyModel()

optim_wrapper = dict(
    optimizer=dict(type='SGD', lr=0.01, weight_decay=0.0001),
    paramwise_cfg=dict(decay_factor=0.5),
    constructor='LayerDecayOptimizerConstructor')

optimizer = build_optim_wrapper(model, optim_wrapper)
```

```
08/23 22:20:26 - mmengine - [4m[37mINFO[0m - layer.linear.weight : lr=0.0025
08/23 22:20:26 - mmengine - [4m[37mINFO[0m - layer.linear.bias : lr=0.0025
08/23 22:20:26 - mmengine - [4m[37mINFO[0m - linear.weight : lr=0.005
08/23 22:20:26 - mmengine - [4m[37mINFO[0m - linear.bias : lr=0.005
```

`add_params` è¢«ç¬¬ä¸€æ¬¡è°ƒç”¨æ—¶ï¼Œ`params` å‚æ•°ä¸ºç©ºåˆ—è¡¨ï¼ˆ`list`ï¼‰ï¼Œ`module` ä¸ºæ¨¡å‹ï¼ˆ`model`ï¼‰ã€‚è¯¦ç»†çš„é‡è½½è§„åˆ™å‚[è€ƒä¼˜åŒ–å™¨å°è£…æ„é€ å™¨æ–‡æ¡£](mmengine.optim.DefaultOptimWrapperConstructor)ã€‚

ç±»ä¼¼åœ°ï¼Œå¦‚æœæƒ³æ„é€ å¤šä¸ªä¼˜åŒ–å™¨ï¼Œä¹Ÿéœ€è¦å®ç°è‡ªå®šä¹‰çš„æ„é€ å™¨ï¼š

```python
@OPTIM_WRAPPER_CONSTRUCTORS.register_module()
class MultipleOptimiWrapperConstructor:
    ...
```

### åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´è¶…å‚

ä¼˜åŒ–å™¨ä¸­çš„è¶…å‚æ•°åœ¨æ„é€ æ—¶åªèƒ½è®¾ç½®ä¸ºä¸€ä¸ªå®šå€¼ï¼Œä»…ä»…ä½¿ç”¨ä¼˜åŒ–å™¨å°è£…ï¼Œå¹¶ä¸èƒ½åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´å­¦ä¹ ç‡ç­‰å‚æ•°ã€‚
åœ¨ MMEngine ä¸­ï¼Œæˆ‘ä»¬å®ç°äº†å‚æ•°è°ƒåº¦å™¨ï¼ˆParameter Schedulerï¼‰ï¼Œä»¥ä¾¿èƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´å‚æ•°ã€‚å…³äºå‚æ•°è°ƒåº¦å™¨çš„ç”¨æ³•è¯·è§[ä¼˜åŒ–å™¨å‚æ•°è°ƒæ•´ç­–ç•¥](./param_scheduler.md)
